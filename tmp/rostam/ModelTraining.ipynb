{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "## Contents\n",
    "1. [BigQuery ML](#BQML)  \n",
    "    1.1 [Training](#BQML_train)  \n",
    "    1.2 [Evaluation](#BQML_eval)  \n",
    "    1.3 [Prediction](#BQML_pred)\n",
    "2. [AutoML Tables](#AutoMLTables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='BQML'></a>\n",
    "# BigQuery ML (BQML)\n",
    "Reference the [CREATE MODEL syntax](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create) to learn about additional model_options for your BigQuery ML model.  \n",
    "<br/>\n",
    "This is a great option if you are very comfortable with SQL and want to quickly iterate and test models.\n",
    "<br/>\n",
    "BigQuery ML takes care of the following preprocessing steps:\n",
    "- Null imputation\n",
    "- One-hot encoding  \n",
    "<br/>\n",
    "<a id='BQML_train'></a>  \n",
    "\n",
    "## Train BQML Model\n",
    "The below example assumes that you have already loaded a preprocessed table into BigQuery (See `Preprocessing.ipynb` for more information on preprocessing).  \n",
    "If you want to additional preprocessing in BigQuery, just add the transformations to the select statement.  \n",
    "<br>The below code sample will only train a model if a model with the same name does not yet exist. This requirement ensures that we can compare model iterations. If you would like to train a new model, change `CREATE MODEL IF NOT EXISTS` to:\n",
    "- `CREATE OR REPLACE MODEL [existing_model_name]`: if you would like to overwrite an existing model, if it exists\n",
    "- `CREATE MODEL IF NOT EXISTS [new_model_name]`: if you would like to create a new model, not overwriting the old model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "CREATE MODEL IF NOT EXISTS `test_upload.sample_model`\n",
    "OPTIONS(\n",
    "    MODEL_TYPE='logistic_reg',\n",
    "    INPUT_LABEL_COLS = ['opened'],\n",
    "    DATA_SPLIT_METHOD = 'CUSTOM',\n",
    "    DATA_SPLIT_COL = 'eval'\n",
    "    ) AS\n",
    "SELECT * EXCEPT(campaign_send_dt, riid) # Use all columns as features besides key columns (campaign_send_dt and riid)\n",
    "FROM `test_upload.pandas_table`\n",
    "\"\"\"\n",
    "\n",
    "client = bigquery.Client()\n",
    "query_job = client.query(sql) # API request\n",
    "result = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='BQML_eval'></a>  \n",
    "## Evaluate BQML Model\n",
    "You have multiple options for analyzing a BQML model's evaluation metrics (i.e. precision, recall, etc...).  \n",
    "<br/>\n",
    "As long as you don't overwrite your old BQML models (i.e. by running `CREATE OR REPLACE MODEL...` and not using a new model name), you'll have a collection of old BigQuery models to reference and compare.\n",
    "\n",
    "### Option #1: Via BigQuery UI\n",
    "Evaluation metrics for each of your models can be found in the [BigQuery UI](https://console.cloud.google.com/bigquery) under the Evaluation tab.\n",
    "<br>\n",
    "<img src=\"img/eval_metrics_bqml.png\" title=\"Eval Metrics\"/>   \n",
    "<br>\n",
    "Available metrics include:\n",
    "- ROC AUC\n",
    "- Log loss\n",
    "- Interactive (for different classification thresholds) precision, recall, accuracy, F1 score metrics\n",
    "- Confusion matrix\n",
    "- Precision-recall curve\n",
    "- Precision and Recall vs. Threshold\n",
    "- ROC Curve  \n",
    "  \n",
    "  \n",
    "### Option #2: Via BigQueryML\n",
    "You can also access Evaluation Metrics using BQML queries, as shown in the samples below. More information about using `ML.EVALUATE` can be found [here](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate).  \n",
    "  \n",
    "You can either use the Python BigQuery API (from this notebook) or the [BigQuery UI](https://console.cloud.google.com/bigquery) to run these queries.\n",
    "\n",
    "If you don't specify a table for `ML.EVALUATE`, the metrics will based on Evaluation data (as specified during model training). If there are more columns in the provided or default table than were used for model training (i.e. key columns), these columns will be ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   precision    recall  accuracy  f1_score  log_loss   roc_auc\n",
      "0   0.618956  0.279507  0.834747  0.385108  0.423249  0.573457\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "SELECT *\n",
    "FROM ML.EVALUATE(MODEL `test_upload.sample_model`)\n",
    "\"\"\"\n",
    "query_job = client.query(sql) # API request\n",
    "result = query_job.to_dataframe()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "You can also specify a table and/or custom threshold.  \n",
    "  \n",
    "If your source table has different column names and transformations than the table used for training, make sure to apply these transformations and rename the columns before using it to query evaluation matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   precision    recall  accuracy  f1_score  log_loss   roc_auc\n",
      "0   0.620039  0.276913  0.834707  0.382845  0.423249  0.573457\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "SELECT *\n",
    "FROM ML.EVALUATE(MODEL `test_upload.sample_model`,\n",
    "    (\n",
    "    SELECT opened,\n",
    "        hist_opens,\n",
    "        hist_sends,\n",
    "        hist_open_rate\n",
    "    FROM `test_upload.pandas_table`\n",
    "    WHERE eval),\n",
    "    STRUCT(0.55 AS threshold))\n",
    "\"\"\"\n",
    "query_job = client.query(sql) # API request\n",
    "result = query_job.to_dataframe()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ROC Curve\n",
    "`ML.ROC_CURVE` returns evaluation metrics for different classification thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql = \"\"\"\n",
    "    SELECT\n",
    "      *\n",
    "    FROM\n",
    "      ML.ROC_CURVE(MODEL `test_upload.sample_model`,\n",
    "        TABLE `test_upload.pandas_table`)\n",
    "\"\"\"\n",
    "query_job = client.query(sql) # API request\n",
    "result = query_job.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>recall</th>\n",
       "      <th>false_positive_rate</th>\n",
       "      <th>true_positives</th>\n",
       "      <th>false_positives</th>\n",
       "      <th>true_negatives</th>\n",
       "      <th>false_negatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.960219</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>81374</td>\n",
       "      <td>18624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.743504</td>\n",
       "      <td>0.052668</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>981</td>\n",
       "      <td>211</td>\n",
       "      <td>81163</td>\n",
       "      <td>17645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.654836</td>\n",
       "      <td>0.121980</td>\n",
       "      <td>0.009131</td>\n",
       "      <td>2272</td>\n",
       "      <td>743</td>\n",
       "      <td>80631</td>\n",
       "      <td>16354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.553906</td>\n",
       "      <td>0.272791</td>\n",
       "      <td>0.039939</td>\n",
       "      <td>5081</td>\n",
       "      <td>3250</td>\n",
       "      <td>78124</td>\n",
       "      <td>13545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.488284</td>\n",
       "      <td>0.293407</td>\n",
       "      <td>0.045838</td>\n",
       "      <td>5465</td>\n",
       "      <td>3730</td>\n",
       "      <td>77644</td>\n",
       "      <td>13161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.317057</td>\n",
       "      <td>0.348599</td>\n",
       "      <td>0.074078</td>\n",
       "      <td>6493</td>\n",
       "      <td>6028</td>\n",
       "      <td>75346</td>\n",
       "      <td>12133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.239029</td>\n",
       "      <td>0.368034</td>\n",
       "      <td>0.088996</td>\n",
       "      <td>6855</td>\n",
       "      <td>7242</td>\n",
       "      <td>74132</td>\n",
       "      <td>11771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.170302</td>\n",
       "      <td>0.378664</td>\n",
       "      <td>0.099037</td>\n",
       "      <td>7053</td>\n",
       "      <td>8059</td>\n",
       "      <td>73315</td>\n",
       "      <td>11573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.167541</td>\n",
       "      <td>0.811178</td>\n",
       "      <td>0.585199</td>\n",
       "      <td>15109</td>\n",
       "      <td>47620</td>\n",
       "      <td>33754</td>\n",
       "      <td>3517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.110966</td>\n",
       "      <td>0.923977</td>\n",
       "      <td>0.810283</td>\n",
       "      <td>17210</td>\n",
       "      <td>65936</td>\n",
       "      <td>15438</td>\n",
       "      <td>1416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.102016</td>\n",
       "      <td>0.969935</td>\n",
       "      <td>0.919593</td>\n",
       "      <td>18066</td>\n",
       "      <td>74831</td>\n",
       "      <td>6543</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.093711</td>\n",
       "      <td>0.988994</td>\n",
       "      <td>0.969868</td>\n",
       "      <td>18421</td>\n",
       "      <td>78922</td>\n",
       "      <td>2452</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.086018</td>\n",
       "      <td>0.996671</td>\n",
       "      <td>0.989948</td>\n",
       "      <td>18564</td>\n",
       "      <td>80556</td>\n",
       "      <td>818</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.055523</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18626</td>\n",
       "      <td>81374</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    threshold    recall  false_positive_rate  true_positives  false_positives  \\\n",
       "0    0.960219  0.000107             0.000000               2                0   \n",
       "1    0.743504  0.052668             0.002593             981              211   \n",
       "2    0.654836  0.121980             0.009131            2272              743   \n",
       "3    0.553906  0.272791             0.039939            5081             3250   \n",
       "4    0.488284  0.293407             0.045838            5465             3730   \n",
       "5    0.317057  0.348599             0.074078            6493             6028   \n",
       "6    0.239029  0.368034             0.088996            6855             7242   \n",
       "7    0.170302  0.378664             0.099037            7053             8059   \n",
       "8    0.167541  0.811178             0.585199           15109            47620   \n",
       "9    0.110966  0.923977             0.810283           17210            65936   \n",
       "10   0.102016  0.969935             0.919593           18066            74831   \n",
       "11   0.093711  0.988994             0.969868           18421            78922   \n",
       "12   0.086018  0.996671             0.989948           18564            80556   \n",
       "13   0.055523  1.000000             1.000000           18626            81374   \n",
       "\n",
       "    true_negatives  false_negatives  \n",
       "0            81374            18624  \n",
       "1            81163            17645  \n",
       "2            80631            16354  \n",
       "3            78124            13545  \n",
       "4            77644            13161  \n",
       "5            75346            12133  \n",
       "6            74132            11771  \n",
       "7            73315            11573  \n",
       "8            33754             3517  \n",
       "9            15438             1416  \n",
       "10            6543              560  \n",
       "11            2452              205  \n",
       "12             818               62  \n",
       "13               0                0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning probability threshold  \n",
    "We can tune the threshold to achieve a certain recall (then you will live with whatever precision you get). Let’s say that we want to make sure to identify at least 70% of opened emails, i.e. we want a recall of 0.7.   \n",
    "<br/>We can identify this graph by simply using looking at the chart above, referencing the interactive plots in the BigQuery UI, or by using the below query to identify the given threshold (as explained [here](https://towardsdatascience.com/how-to-tune-a-bigquery-ml-classification-model-to-achieve-a-desired-precision-or-recall-e4d40b93016a))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   threshold    recall  false_positive_rate  from_desired_recall\n",
      "0   0.167541  0.810714             0.586374             0.110714\n"
     ]
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    WITH roc AS (\n",
    "        SELECT\n",
    "          *\n",
    "        FROM\n",
    "          ML.ROC_CURVE(MODEL `test_upload.sample_model`,\n",
    "            (SELECT opened,\n",
    "                hist_opens,\n",
    "                hist_sends,\n",
    "                hist_open_rate\n",
    "            FROM `test_upload.pandas_table`\n",
    "            WHERE eval = False)\n",
    "            ))\n",
    "    SELECT\n",
    "        threshold,\n",
    "        recall, false_positive_rate,\n",
    "        ABS(recall - 0.7) AS from_desired_recall\n",
    "    FROM roc\n",
    "    ORDER BY from_desired_recall ASC\n",
    "    LIMIT 1    \n",
    "\"\"\"\n",
    "query_job = client.query(sql) # API request\n",
    "result = query_job.to_dataframe()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "More information about BQML Confusion Matrices can be found [here](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>expected_label</th>\n",
       "      <th>_0</th>\n",
       "      <th>_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19575</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3345</td>\n",
       "      <td>1281</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   expected_label     _0    _1\n",
       "0               0  19575   785\n",
       "1               1   3345  1281"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.CONFUSION_MATRIX(MODEL `test_upload.sample_model`,\n",
    "  (\n",
    "    SELECT *\n",
    "    FROM `test_upload.pandas_table`\n",
    "    WHERE eval),\n",
    "    STRUCT(0.55 AS threshold)\n",
    "    )\n",
    "\"\"\"\n",
    "query_job = client.query(sql) # API request\n",
    "result = query_job.to_dataframe()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Info\n",
    "`ML.FEATURE_INFO`, as explained [here](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-feature), returns information about input features used to train the model including:\n",
    "- input: name of the column\n",
    "- min: sample minimum (NULL if categorical)\n",
    "- max: sample maximum (NULL if categorical)\n",
    "- mean: sample average (NULL if categorical)\n",
    "- stddev: sample standard deviation (NULL if categorical)\n",
    "- categorical_count: number of categories (NULL if not categorical)\n",
    "- null_count - number of NULLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>median</th>\n",
       "      <th>stddev</th>\n",
       "      <th>category_count</th>\n",
       "      <th>null_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hist_opens</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.228517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.633862</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hist_sends</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.008878</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.283603</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hist_open_rate</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.215606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370378</td>\n",
       "      <td>None</td>\n",
       "      <td>35713</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            input  min   max      mean  median    stddev category_count  \\\n",
       "0      hist_opens  0.0   8.0  0.228517     0.0  0.633862           None   \n",
       "1      hist_sends  0.0  10.0  1.008878     1.0  1.283603           None   \n",
       "2  hist_open_rate  0.0   1.0  0.215606     0.0  0.370378           None   \n",
       "\n",
       "   null_count  \n",
       "0           0  \n",
       "1           0  \n",
       "2       35713  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    SELECT\n",
    "      *\n",
    "    FROM\n",
    "      ML.FEATURE_INFO(MODEL `test_upload.sample_model`)\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(sql) # API request\n",
    "result = query_job.to_dataframe()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights\n",
    "The `ML.WEIGHTS` function allows you to see the underlying weights used by a model during prediction, as explained [here](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-weights).  \n",
    "  \n",
    "Our example does not include categorical columns. However, if we want to look at weights for categorical (one-hot encoded) features, use the following query:\n",
    "```\n",
    "SELECT\n",
    "  category,\n",
    "  weight\n",
    "FROM\n",
    "  UNNEST((\n",
    "    SELECT\n",
    "      category_weights\n",
    "    FROM\n",
    "      ML.WEIGHTS(MODEL `[dataset_id].[model_name]`)\n",
    "    WHERE\n",
    "      processed_input = '[categorical_column]'))\n",
    "```  \n",
    "It's also very simple to look at the weights of numeric or boolean features, as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>processed_input</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hist_opens</td>\n",
       "      <td>0.518016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hist_sends</td>\n",
       "      <td>-0.094116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hist_open_rate</td>\n",
       "      <td>1.779359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>__INTERCEPT__</td>\n",
       "      <td>-1.986794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  processed_input    weight\n",
       "0      hist_opens  0.518016\n",
       "1      hist_sends -0.094116\n",
       "2  hist_open_rate  1.779359\n",
       "3   __INTERCEPT__ -1.986794"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    SELECT\n",
    "      processed_input, weight\n",
    "    FROM\n",
    "      ML.WEIGHTS(MODEL `test_upload.sample_model`)\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(sql) # API request\n",
    "result = query_job.to_dataframe()\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='BQML_pred'></a>  \n",
    "## Predictions using BQML Model\n",
    "The `ML.PREDICT` function can be used to predict outcomes using the model, as explained [here](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predicted_opened</th>\n",
       "      <th>predicted_opened_probs</th>\n",
       "      <th>riid</th>\n",
       "      <th>campaign_send_dt</th>\n",
       "      <th>opened</th>\n",
       "      <th>hist_opens</th>\n",
       "      <th>hist_sends</th>\n",
       "      <th>hist_open_rate</th>\n",
       "      <th>eval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'prob': 0.1675412616617039, 'label': 1}, {'p...</td>\n",
       "      <td>737847182</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'prob': 0.1675412616617039, 'label': 1}, {'p...</td>\n",
       "      <td>566134962</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'prob': 0.1675412616617039, 'label': 1}, {'p...</td>\n",
       "      <td>849236702</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'prob': 0.1675412616617039, 'label': 1}, {'p...</td>\n",
       "      <td>825551142</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>[{'prob': 0.1675412616617039, 'label': 1}, {'p...</td>\n",
       "      <td>825759702</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predicted_opened                             predicted_opened_probs  \\\n",
       "0                 0  [{'prob': 0.1675412616617039, 'label': 1}, {'p...   \n",
       "1                 0  [{'prob': 0.1675412616617039, 'label': 1}, {'p...   \n",
       "2                 0  [{'prob': 0.1675412616617039, 'label': 1}, {'p...   \n",
       "3                 0  [{'prob': 0.1675412616617039, 'label': 1}, {'p...   \n",
       "4                 0  [{'prob': 0.1675412616617039, 'label': 1}, {'p...   \n",
       "\n",
       "        riid campaign_send_dt  opened  hist_opens  hist_sends  hist_open_rate  \\\n",
       "0  737847182       2018-01-01       0           0           0             NaN   \n",
       "1  566134962       2018-01-01       0           0           0             NaN   \n",
       "2  849236702       2018-01-01       0           0           0             NaN   \n",
       "3  825551142       2018-01-01       0           0           0             NaN   \n",
       "4  825759702       2018-01-01       0           0           0             NaN   \n",
       "\n",
       "   eval  \n",
       "0  True  \n",
       "1  True  \n",
       "2  True  \n",
       "3  True  \n",
       "4  True  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"\n",
    "    SELECT\n",
    "      *\n",
    "    FROM\n",
    "      ML.PREDICT(MODEL `test_upload.sample_model`,\n",
    "      (\n",
    "        SELECT *\n",
    "        FROM `test_upload.pandas_table`\n",
    "        WHERE eval),\n",
    "        STRUCT(0.55 AS threshold)\n",
    "        )\n",
    "\"\"\"\n",
    "\n",
    "query_job = client.query(sql) # API request\n",
    "result = query_job.to_dataframe()\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The predicted probabilities for each class are stored in a nested array. We can use BigQuery's `UNNEST` function to find the probabilities of an opened email.  \n",
    "\n",
    "Notice that the name of the prediction column (`predicted_opened`) is formatted `predicted_[name_of_label_column]` and the column containing the nested probabilities (`predicted_opened_probs`) is formatted `predicted_[name_of_label_column]_probs`. You will need to replace the `opened` with the name of your label column in the code samples below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>riid</th>\n",
       "      <th>campaign_send_dt</th>\n",
       "      <th>predicted_opened</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>737847182</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>566134962</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>849236702</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>825551142</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>825759702</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        riid campaign_send_dt  predicted_opened      prob\n",
       "0  737847182       2018-01-01                 0  0.167541\n",
       "1  566134962       2018-01-01                 0  0.167541\n",
       "2  849236702       2018-01-01                 0  0.167541\n",
       "3  825551142       2018-01-01                 0  0.167541\n",
       "4  825759702       2018-01-01                 0  0.167541"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql = \"\"\"WITH results  AS (\n",
    "      SELECT\n",
    "        *\n",
    "      FROM\n",
    "        ML.PREDICT(MODEL `test_upload.sample_model`,\n",
    "        (\n",
    "          SELECT *\n",
    "          FROM `test_upload.pandas_table`\n",
    "          WHERE eval),\n",
    "          STRUCT(0.55 AS threshold)\n",
    "          ))\n",
    "    SELECT riid,\n",
    "        campaign_send_dt,\n",
    "        predicted_opened, # Replace with predict_[name_of_label_column]\n",
    "        probs.prob\n",
    "    FROM results, UNNEST(predicted_opened_probs) as probs # Replace table in UNNEST(...) with predict_[name_of_label_column]_probs\n",
    "    WHERE probs.label = 1\"\"\"\n",
    "\n",
    "query_job = client.query(sql) # API request\n",
    "result = query_job.to_dataframe()\n",
    "result.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='AutoMLTables'></a>\n",
    "# AutoML Tables\n",
    "## Training\n",
    "### Option #1 UI\n",
    "https://console.cloud.google.com/automl-tables\n",
    "Import Data from BigQuery\n",
    "Downside: Import can take awhile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
